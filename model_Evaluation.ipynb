{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from scipy import stats\n",
    "from data_processing import *\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.base import TransformerMixin \n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble  import ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-way hold out method for hyperparameter tuning  \n",
    "# (train / validation / test ) with 5-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x , y , num , cat = data_prep()\n",
    "\n",
    "xtrain , xtest , ytrain , ytest = train_test_split(x , y , test_size = 0.25 , random_state = 10 )\n",
    "\n",
    "classifiers = [\n",
    "        ('KNN' , KNeighborsClassifier() , {\n",
    "                                            'KNN__algorithm':('auto','ball_tree', 'kd_tree', 'brute'),\n",
    "                                            'KNN__n_neighbors' : stats.randint(4 ,40),\n",
    "                                            'KNN__p' : stats.randint(1 ,5),\n",
    "                                            'KNN__weights' : ('uniform' , 'distance')\n",
    "            }),\n",
    "        ('ETclf' , ExtraTreesClassifier() , {\n",
    "                            'ETclf__n_estimators': stats.randint(10 ,500),\n",
    "                            'ETclf__criterion' :('gini' , 'entropy'), \n",
    "                            'ETclf__max_depth': stats.randint(10 ,50), \n",
    "                            'ETclf__max_features': ('sqrt' , 'log2', 'auto') , \n",
    "                                            }), \n",
    "        ('SGD' , SGDClassifier() , {\n",
    "                    'SGD__loss' : ('hinge' , 'log'),\n",
    "                    'SGD__penalty' : ('l1' , 'l2' , 'elasticnet'),\n",
    "                    'SGD__alpha' : stats.uniform(loc = 0 , scale = 0.5)\n",
    "            } )\n",
    "]\n",
    "\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "\n",
    "    ('handle_MV' , Impute_MV()),\n",
    "\n",
    "    ('union' , FeatureUnion([\n",
    "        ('numerical' , Pipeline(steps = [\n",
    "            ('extract' , ColumnExtractor(num)),\n",
    "            ('scale' , StandardScaler())\n",
    "            ])),\n",
    "        ('categorical' , Pipeline(steps = [\n",
    "            ('extract' , ColumnExtractor(cat)),\n",
    "            ('one_hot' , One_Hot())\n",
    "            ]))\n",
    "\n",
    "\n",
    "        ]))\n",
    "\n",
    "\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfiles = [f for f in listdir('data') if isfile(join('data', f))]\n",
    "\n",
    "for name , clf , params in classifiers : \n",
    "\n",
    "    url = f'data/{name}_model_selection_algo.csv'\n",
    "    if url[5:] not in onlyfiles : \n",
    "        pipe.steps.append((name , clf ))\n",
    "\n",
    "        cv = StratifiedKFold(5)\n",
    "        grid = RandomizedSearchCV(pipe , params , cv = cv , n_jobs = -1 , scoring = 'accuracy' )\n",
    "        grid.fit(xtrain , ytrain)\n",
    "        means = grid.cv_results_['mean_test_score']\n",
    "        stds = grid.cv_results_['std_test_score']\n",
    "        params = grid.cv_results_['params']\n",
    "        df = pd.DataFrame({\n",
    "                'means' : means,\n",
    "                'stds' : stds,\n",
    "                'params' : params\n",
    "        })\n",
    "\n",
    "        df.to_csv(url)\n",
    "        pipe.steps = pipe.steps[:-1]\n",
    "    else : \n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "ETclf = pd.read_csv('data/ETclf_model_selection_algo.csv').sort_values(by='means' , ascending = False)\n",
    "SGD =  pd.read_csv('data/SGD_model_selection_algo.csv').sort_values(by='means' , ascending = False)\n",
    "KNN = pd.read_csv('data/KNN_model_selection_algo.csv').sort_values(by='means' , ascending = False)\n",
    "best_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.44      0.42      0.43       541\n",
      "           B       0.26      0.38      0.31       320\n",
      "           C       0.61      0.56      0.58       516\n",
      "           D       0.71      0.64      0.67       640\n",
      "\n",
      "    accuracy                           0.52      2017\n",
      "   macro avg       0.51      0.50      0.50      2017\n",
      "weighted avg       0.54      0.52      0.53      2017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ET = ExtraTreesClassifier()\n",
    "cv = StratifiedKFold(5)\n",
    "params = {}\n",
    "for k in eval(ETclf.iloc[0 , -1]).keys() : \n",
    "    params[k[7:]] = eval(ETclf.iloc[0 , -1])[k]\n",
    "ET.set_params(**params)\n",
    "ET.fit(pipe.fit_transform(xtrain) , ytrain)\n",
    "pred = ET.predict(pipe.fit_transform(xtest))\n",
    "print(classification_report(pred , ytest))\n",
    "\n",
    "\n",
    "score = cross_val_score(ET ,pipe.fit_transform(x) , y , cv = cv , scoring = 'accuracy' )\n",
    "best_models['ETclf'] = score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.43      0.44      0.43       493\n",
      "           B       0.34      0.39      0.36       395\n",
      "           C       0.61      0.56      0.58       523\n",
      "           D       0.68      0.65      0.67       606\n",
      "\n",
      "    accuracy                           0.52      2017\n",
      "   macro avg       0.51      0.51      0.51      2017\n",
      "weighted avg       0.53      0.52      0.53      2017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "cv = StratifiedKFold(5)\n",
    "params = {}\n",
    "for k in eval(KNN.iloc[0 , -1]).keys() : \n",
    "    params[k[5:]] = eval(KNN.iloc[0 , -1])[k]\n",
    "knn.set_params(**params)\n",
    "knn.fit(pipe.fit_transform(xtrain) , ytrain)\n",
    "pred = knn.predict(pipe.fit_transform(xtest))\n",
    "print(classification_report(pred , ytest))\n",
    "\n",
    "\n",
    "score = cross_val_score(knn ,pipe.fit_transform(x) , y , cv = cv , scoring = 'accuracy' )\n",
    "best_models['KNN'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.46      0.44      0.45       537\n",
      "           B       0.09      0.40      0.15       105\n",
      "           C       0.75      0.47      0.58       763\n",
      "           D       0.67      0.63      0.65       612\n",
      "\n",
      "    accuracy                           0.51      2017\n",
      "   macro avg       0.49      0.48      0.46      2017\n",
      "weighted avg       0.62      0.51      0.54      2017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier()\n",
    "cv = StratifiedKFold(5)\n",
    "params = {}\n",
    "for k in eval(SGD.iloc[0 , -1]).keys() : \n",
    "    params[k[5:]] = eval(SGD.iloc[0 , -1])[k]\n",
    "sgd.set_params(**params)\n",
    "sgd.fit(pipe.fit_transform(xtrain) , ytrain)\n",
    "pred = sgd.predict(pipe.fit_transform(xtest))\n",
    "print(classification_report(pred , ytest))\n",
    "\n",
    "score = cross_val_score(sgd ,pipe.fit_transform(x) , y , cv = cv , scoring = 'accuracy' )\n",
    "best_models['SGD'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.44      0.45      0.45       497\n",
      "           B       0.29      0.39      0.33       342\n",
      "           C       0.60      0.56      0.58       514\n",
      "           D       0.73      0.63      0.68       664\n",
      "\n",
      "    accuracy                           0.53      2017\n",
      "   macro avg       0.52      0.51      0.51      2017\n",
      "weighted avg       0.55      0.53      0.54      2017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_params_ = {'max_depth': 11, 'max_features': 'log2', 'n_estimators': 406}\n",
    "RF = RandomForestClassifier().set_params(**best_params_)\n",
    "RF.fit(pipe.fit_transform(xtrain) , ytrain)\n",
    "pred = RF.predict(pipe.fit_transform(xtest))\n",
    "print(classification_report(pred , ytest))\n",
    "\n",
    "\n",
    "score = cross_val_score(RF ,pipe.fit_transform(x) , y , cv = cv , scoring = 'accuracy' )\n",
    "best_models['RFclf'] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation : \n",
    "it seems that all models selected have the same predictive pattern , we can see that the precision percentage are higher for class C and D which mean that when the model predict (C / D) it is more likely to be actually (C / D) , same thing from recall when the classes are actually (C / d) it is more likely that the models will correctly predict those classes .\n",
    "\n",
    "on the other side we see less recall / precision for B which mean that the models cannot predict that class well  , but for class A it is around 50 % for recall/precision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x141719f0>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig , ax = plt.subplots(1,1 , figsize = (16 , 10))\n",
    "\n",
    "models =pd.DataFrame(best_models)\n",
    "col = models.columns\n",
    "df = models.melt( value_vars = col , value_name = 'col2' )\n",
    "sns.boxplot(df.variable , df.col2 , ax = ax )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation :\n",
    "\n",
    "this plot is showing a box plot of the accuracies of 5-fold CV for each model , we can see that there is no much difference between the models , the Random forest classifier seems to perform better than the others  while on the other side the SGD model seems to have high variance , which mean small fluctuation of the model result in big shift of the accuracy 'overfitting'. to see if there is a significant difference we need to preform the F-test between the models  ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_model_1 = sgd.predict(pipe.fit_transform(xtest))\n",
    "y_model_2 = ET.predict(pipe.fit_transform(xtest))\n",
    "y_model_3 = RF.predict(pipe.fit_transform(xtest))\n",
    "y_model_4 = knn.predict(pipe.fit_transform(xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F: 0.235\n",
      "p-value: 0.791\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.evaluate import ftest\n",
    "f, p_value = ftest(np.asarray(ytest), \n",
    "                   y_model_1, \n",
    "                   y_model_2, \n",
    "                   y_model_3,\n",
    "                   y_model_4)\n",
    "\n",
    "print('F: %.3f' % f)\n",
    "print('p-value: %.3f' % p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the p-value is highe than threshold $\\alpha = 0.05$ which mean we failed to reject the null hypothesis , meaning that there is no different between the models , now the other step would be taking account the variance , in this case we will go from comparing models to comparing algorithms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing algorithms using 5x2CV F-test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra vs KNeig\n",
      "F statistic: 0.585\n",
      "p value: 0.780\n",
      "=====================\n",
      "\n",
      "Extra vs Rando\n",
      "F statistic: 7.401\n",
      "p value: 0.020\n",
      "=====================\n",
      "\n",
      "Extra vs SGDCl\n",
      "F statistic: 4.220\n",
      "p value: 0.063\n",
      "=====================\n",
      "\n",
      "KNeig vs Extra\n",
      "F statistic: 0.609\n",
      "p value: 0.764\n",
      "=====================\n",
      "\n",
      "KNeig vs Rando\n",
      "F statistic: 3.127\n",
      "p value: 0.110\n",
      "=====================\n",
      "\n",
      "KNeig vs SGDCl\n",
      "F statistic: 3.124\n",
      "p value: 0.110\n",
      "=====================\n",
      "\n",
      "Rando vs Extra\n",
      "F statistic: 3.544\n",
      "p value: 0.088\n",
      "=====================\n",
      "\n",
      "Rando vs KNeig\n",
      "F statistic: 3.616\n",
      "p value: 0.084\n",
      "=====================\n",
      "\n",
      "Rando vs SGDCl\n",
      "F statistic: 7.086\n",
      "p value: 0.022\n",
      "=====================\n",
      "\n",
      "SGDCl vs Extra\n",
      "F statistic: 2.650\n",
      "p value: 0.147\n",
      "=====================\n",
      "\n",
      "SGDCl vs KNeig\n",
      "F statistic: 16.089\n",
      "p value: 0.003\n",
      "=====================\n",
      "\n",
      "SGDCl vs Rando\n",
      "F statistic: 16.619\n",
      "p value: 0.003\n",
      "=====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "from mlxtend.evaluate import combined_ftest_5x2cv\n",
    "\n",
    "for i , j in product(*[[ET , knn , RF , sgd] ,[ET , knn , RF , sgd]]):\n",
    "    if i!=j :\n",
    "        \n",
    "        f, p = combined_ftest_5x2cv(i,\n",
    "                                    j,\n",
    "                                    X=pipe.fit_transform(xtrain),\n",
    "                                    y=np.asarray(ytrain), \n",
    "                                   scoring='accuracy')\n",
    "        \n",
    "        print(f'{str(i)[:5]} vs {str(j)[:5]}')\n",
    "        print('F statistic: %.3f' % f)\n",
    "        print('p value: %.3f' % p)\n",
    "        print('=====================\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation :\n",
    "\n",
    "the difference occure between the sgd classifier and ET and RF which mean the high variance of sgd will eliminate that choice and leaves us with just RF and ET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower = 0.5022503372546827 , upper = 0.5458408873362939\n",
      "difference 0.04359055008161117\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "RF = RandomForestClassifier().set_params(**best_params_)\n",
    "RF.fit(pipe.fit_transform(xtrain) , ytrain)\n",
    "pred = RF.predict(pipe.fit_transform(xtest))\n",
    "\n",
    "cm = confusion_matrix(ytest , pred)\n",
    "num_acc = np.trace(cm)\n",
    "lower , upper = proportion_confint(num_acc , ytest.shape[0] , 0.05)\n",
    "print(f'lower = {lower} , upper = {upper}')\n",
    "print(f'difference {upper - lower}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower = 0.49480034429928793 , upper = 0.5384173056759228\n",
      "difference 0.0436169613766349\n"
     ]
    }
   ],
   "source": [
    "ET = ExtraTreesClassifier()\n",
    "params = {}\n",
    "for k in eval(ETclf.iloc[0 , -1]).keys() : \n",
    "    params[k[7:]] = eval(ETclf.iloc[0 , -1])[k]\n",
    "ET.set_params(**params)\n",
    "ET.fit(pipe.fit_transform(xtrain) , ytrain)\n",
    "pred = ET.predict(pipe.fit_transform(xtest))\n",
    "\n",
    "cm = confusion_matrix(ytest , pred)\n",
    "num_acc = np.trace(cm)\n",
    "lower , upper = proportion_confint(num_acc , ytest.shape[0] , 0.05)\n",
    "print(f'lower = {lower} , upper = {upper}')\n",
    "print(f'difference {upper - lower}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "both models seems to be narrowed almost the same amount , but the RF seems to be shifted forward more than the ET , now we should see if the models reach their capacities or they need more data . \n",
    "\n",
    "To do that we will train the model on the whole data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.63      0.58      0.61      2127\n",
      "           B       0.44      0.60      0.51      1345\n",
      "           C       0.66      0.63      0.64      2061\n",
      "           D       0.80      0.72      0.76      2535\n",
      "\n",
      "    accuracy                           0.64      8068\n",
      "   macro avg       0.63      0.63      0.63      8068\n",
      "weighted avg       0.66      0.64      0.65      8068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ET = ExtraTreesClassifier()\n",
    "cv = StratifiedKFold(5)\n",
    "params = {}\n",
    "for k in eval(ETclf.iloc[0 , -1]).keys() : \n",
    "    params[k[7:]] = eval(ETclf.iloc[0 , -1])[k]\n",
    "ET.set_params(**params)\n",
    "ET.fit(pipe.fit_transform(x) , y)\n",
    "pred = ET.predict(pipe.fit_transform(x))\n",
    "print(classification_report(pred , y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.69      0.67      0.68      2032\n",
      "           B       0.51      0.67      0.58      1400\n",
      "           C       0.70      0.67      0.68      2074\n",
      "           D       0.85      0.75      0.80      2562\n",
      "\n",
      "    accuracy                           0.70      8068\n",
      "   macro avg       0.69      0.69      0.69      8068\n",
      "weighted avg       0.71      0.70      0.70      8068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier().set_params(**best_params_)\n",
    "RF.fit(pipe.fit_transform(x) , y)\n",
    "pred = RF.predict(pipe.fit_transform(x))\n",
    "print(classification_report(pred , y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation \n",
    "the model RF is still the best choice and the accuracy increased to 70% which mean the model need more data to improve more "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
